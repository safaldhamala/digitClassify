{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T00:45:16.739294Z","iopub.execute_input":"2024-12-03T00:45:16.739713Z","iopub.status.idle":"2024-12-03T00:45:17.118952Z","shell.execute_reply.started":"2024-12-03T00:45:16.739679Z","shell.execute_reply":"2024-12-03T00:45:17.117926Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T00:45:20.356043Z","iopub.execute_input":"2024-12-03T00:45:20.356560Z","iopub.status.idle":"2024-12-03T00:45:24.708757Z","shell.execute_reply.started":"2024-12-03T00:45:20.356525Z","shell.execute_reply":"2024-12-03T00:45:24.707751Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T00:45:26.081873Z","iopub.execute_input":"2024-12-03T00:45:26.082259Z","iopub.status.idle":"2024-12-03T00:45:26.106830Z","shell.execute_reply.started":"2024-12-03T00:45:26.082224Z","shell.execute_reply":"2024-12-03T00:45:26.105751Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 785 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"data = np.array(data)\n# data[:,0] # prints the first column (label)\nm, n = data.shape\nnp.random.shuffle(data) # to prevent the model from learning unintended biases\n\n# validation set\ndata_dev = data[0:1000].T # first 1000 examples, and transposing, so one column instead of row reprsnts an image now ( just for easiness to do calculations, if using tensorflow or pytorch no need to transpose, these libraries are written to handle rows )\nY_dev = data_dev[0] # so instead of [:, 0](for columns), use [0] now to return the label array (now the first row instead of first column)\nX_dev = data_dev[1:n]\nX_dev = X_dev / 255.\n\n# training set\ndata_train = data[1000:m].T # remaining examples from 1000 to m\nY_train = data_train[0]\nX_train = data_train[1:n]\nX_train = X_train / 255.\n\n# print(X_train[:, 0].shape) # should print 784 i.e. the number of items in each column which is the number of pixels per image\nprint(X_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T00:46:01.982266Z","iopub.execute_input":"2024-12-03T00:46:01.983015Z","iopub.status.idle":"2024-12-03T00:46:02.763969Z","shell.execute_reply.started":"2024-12-03T00:46:01.982980Z","shell.execute_reply":"2024-12-03T00:46:02.763004Z"}},"outputs":[{"name":"stdout","text":"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# initialize parameters\n# creating a neural net with 3 layers\n# input layer wiht 784 units\n# 1st and 2nd (output) layer with 10 units\n# all random at first, then adjusted later in backprop\n\ndef init_params():\n    W1 = np.random.rand(10, 784) - 0.5 # weights for the layer (comin from input layer)\n    b1 = np.zeros((10, 1)) # biases for the 1st layer\n    W2 = np.random.rand(10, 10) - 0.5 # weights for the output layer\n    b2 = np.zeros((10, 1)) # biases for the output layer\n    return W1, b1, W2, b2\n\ndef ReLU(Z):\n    return np.maximum(Z,0) # rectified linear unit, an activation function\n\ndef softmax(Z):\n    A = np.exp(Z) / sum(np.exp(Z))\n    return A # another activation func used at the output layer to get probabilities (betn 0 and 1)\n    \ndef forward_prop(W1, b1, W2, b2, X):\n    Z1 = W1.dot(X) + b1  # Z1 is the unactivated 1st layer\n    A1 = ReLU(Z1)        # Activated Z1 (A1)\n    Z2 = W2.dot(A1) + b2 # same thing\n    A2 = softmax(Z2)\n    return Z1, A1, Z2, A2\n\ndef ReLU_deriv(Z):\n    return Z > 0\n\ndef one_hot(Y): # remember Y is a row matrix, one_hot creates the matrix [0,0,1,0,...,0] for '2' and likewise for all images, this process is called one-hot encoding, look it up for more info\n    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n    # Y.size is the number of examples, Y.max is 9 so +1 is 10, creates a zero matrix of size m x 10\n\n    one_hot_Y[np.arange(Y.size), Y] = 1\n    # a cool way of one hot encoding \n\n    one_hot_Y = one_hot_Y.T # each column is an example now\n    return one_hot_Y\n    \ndef backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n    one_hot_Y = one_hot(Y)\n    dZ2 = A2 - one_hot_Y\n    dW2 = 1 / m * dZ2.dot(A1.T)\n    db2 = 1 / m * np.sum(dZ2)\n    dZ1 = W2.T.dot(dZ2) * ReLU_deriv(Z1)\n    dW1 = 1 / m * dZ1.dot(X.T)\n    db1 = 1 / m * np.sum(dZ1)\n    return dW1, db1, dW2, db2\n\ndef update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha): # alpha, the learning rate, is what we pass (custom)\n    W1 = W1 - alpha * dW1\n    b1 = b1 - alpha * db1    \n    W2 = W2 - alpha * dW2  \n    b2 = b2 - alpha * db2    \n    return W1, b1, W2, b2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T00:49:26.452814Z","iopub.execute_input":"2024-12-03T00:49:26.453191Z","iopub.status.idle":"2024-12-03T00:49:26.464300Z","shell.execute_reply.started":"2024-12-03T00:49:26.453157Z","shell.execute_reply":"2024-12-03T00:49:26.463435Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def get_predictions(A2): # activated 2nd layer\n    return np.argmax(A2, 0) # argmax returns the index of the highest value (probability in this case)\n\ndef get_accuracy(predictions, Y):\n    print(predictions, Y)\n    return np.sum(predictions == Y) / Y.size\n    # sum(predictions == Y) counts the number of True's we get from comparing predictions and Y\n    # then we divide that by actual size of Y to get accuracy\n    \ndef gradient_descent(X, Y, alpha, iterations):\n    W1, b1, W2, b2 = init_params()\n    for i in range(iterations):\n        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n        if i % 10 == 0: # every 10 iterations, we're going to check the progress\n            print(\"Iteration: \", i)\n            predictions = get_predictions(A2) \n            print(get_accuracy(predictions, Y)) \n    return W1, b1, W2, b2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T00:50:58.878176Z","iopub.execute_input":"2024-12-03T00:50:58.879106Z","iopub.status.idle":"2024-12-03T00:50:58.885846Z","shell.execute_reply.started":"2024-12-03T00:50:58.879068Z","shell.execute_reply":"2024-12-03T00:50:58.884897Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 500)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T00:51:03.602998Z","iopub.execute_input":"2024-12-03T00:51:03.603599Z","iopub.status.idle":"2024-12-03T00:51:56.005635Z","shell.execute_reply.started":"2024-12-03T00:51:03.603565Z","shell.execute_reply":"2024-12-03T00:51:56.004481Z"}},"outputs":[{"name":"stdout","text":"Iteration:  0\n[1 4 1 ... 1 3 3] [8 1 9 ... 7 8 5]\n0.072\nIteration:  10\n[6 6 8 ... 7 6 6] [8 1 9 ... 7 8 5]\n0.20560975609756096\nIteration:  20\n[8 6 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.3110487804878049\nIteration:  30\n[8 6 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.3999756097560976\nIteration:  40\n[8 6 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.4690731707317073\nIteration:  50\n[8 8 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.5227317073170732\nIteration:  60\n[8 8 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.5678780487804878\nIteration:  70\n[8 8 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.605609756097561\nIteration:  80\n[8 8 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.6362439024390244\nIteration:  90\n[8 8 9 ... 1 3 5] [8 1 9 ... 7 8 5]\n0.6599268292682927\nIteration:  100\n[8 8 9 ... 1 3 5] [8 1 9 ... 7 8 5]\n0.680829268292683\nIteration:  110\n[8 8 9 ... 1 3 5] [8 1 9 ... 7 8 5]\n0.6979512195121951\nIteration:  120\n[8 8 9 ... 1 3 5] [8 1 9 ... 7 8 5]\n0.7112682926829268\nIteration:  130\n[8 8 9 ... 1 3 5] [8 1 9 ... 7 8 5]\n0.7235853658536585\nIteration:  140\n[8 8 9 ... 1 3 5] [8 1 9 ... 7 8 5]\n0.7355365853658536\nIteration:  150\n[8 8 9 ... 1 3 5] [8 1 9 ... 7 8 5]\n0.7450975609756098\nIteration:  160\n[8 8 9 ... 1 3 5] [8 1 9 ... 7 8 5]\n0.7533414634146341\nIteration:  170\n[8 8 9 ... 1 3 5] [8 1 9 ... 7 8 5]\n0.7604878048780488\nIteration:  180\n[8 8 9 ... 1 3 5] [8 1 9 ... 7 8 5]\n0.7678292682926829\nIteration:  190\n[8 8 9 ... 1 3 5] [8 1 9 ... 7 8 5]\n0.7742682926829269\nIteration:  200\n[8 8 9 ... 1 3 5] [8 1 9 ... 7 8 5]\n0.7799024390243903\nIteration:  210\n[8 8 9 ... 1 3 5] [8 1 9 ... 7 8 5]\n0.7861219512195122\nIteration:  220\n[8 8 9 ... 1 3 5] [8 1 9 ... 7 8 5]\n0.7913658536585366\nIteration:  230\n[8 8 9 ... 1 3 5] [8 1 9 ... 7 8 5]\n0.795609756097561\nIteration:  240\n[8 8 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.8000975609756098\nIteration:  250\n[8 8 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.8039756097560976\nIteration:  260\n[8 8 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.808\nIteration:  270\n[8 8 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.8114878048780488\nIteration:  280\n[8 8 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.8143170731707317\nIteration:  290\n[8 8 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.8166585365853658\nIteration:  300\n[8 8 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.8193658536585365\nIteration:  310\n[8 8 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.8220731707317073\nIteration:  320\n[8 8 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.8250487804878048\nIteration:  330\n[8 8 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.8274146341463414\nIteration:  340\n[8 8 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.8294146341463414\nIteration:  350\n[8 8 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.8314878048780487\nIteration:  360\n[8 8 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.8331219512195122\nIteration:  370\n[8 8 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.8347317073170731\nIteration:  380\n[8 8 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.8363658536585366\nIteration:  390\n[8 1 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.8382682926829268\nIteration:  400\n[8 1 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.84\nIteration:  410\n[8 1 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.8416829268292683\nIteration:  420\n[8 1 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.8433414634146341\nIteration:  430\n[8 1 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.844780487804878\nIteration:  440\n[8 1 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.8456585365853658\nIteration:  450\n[8 1 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.8468780487804878\nIteration:  460\n[8 1 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.8484390243902439\nIteration:  470\n[8 1 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.8494146341463414\nIteration:  480\n[8 1 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.8504634146341463\nIteration:  490\n[8 1 9 ... 7 3 5] [8 1 9 ... 7 8 5]\n0.851609756097561\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}